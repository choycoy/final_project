1. My project is about prediction of student performance and recommendation of questions in adaptive learning environment. 

2. First, adaptive learning is an educational approach that leverages data and technology to personalise the learning experience for individual learners.It aims to tailor instruction, content, and assessment to the unique needs, abilities, and preferences of each learner, allowing them to learn at their own pace and in a way that maximises their understanding and retention of the material. 

3. Then, the dataset I used for this project is called EdNet. It is a dataset of all student-system interactions collected over 2 years by an AI tutoring service platform and it is the largest dataset in education available to the public in terms of the total number of students and interactions. It contains various features of students' actions such as which learning material they have consumed and responded, how much time they have spent for solving a given question. I had a total 13619(thirteen thousand six hundred nineteen) questions and 27904657(twenty-seven million nine hundred four thousand six hundred fifty-seven) interactions between students and system. 

4. Among many attributes in the dataset, I mainly used user id, question id, user answer, correct answer and elapsed time attributes for prediction and recommendation. Elapsed time represents the time taken by the student to answer each question in milliseconds. 

5. In this project, the predictive model is developed to predict if the student will answer correctly on the next question by analysing student's past performance such as elapsed time and correctness rate. Correctness rate is a metric used to assess how well a student predicts the accurate answers to questions. This rate is defined as the ratio of correct responses out of the total number of questions attempted by the student.

6.Then, I calculated the average, minimum, and maximum elapsed time for each user. The average elapsed time represents the average time a student takes to answer questions,This feature can provide information about the student's typical response speed. If a student consistently answers questions quickly, it might indicate confidence or familiarity with the material. On the other hand, if the average time is long, it might suggest that the student spends more time on each question, possibly indicating difficulty or uncertainty. 

and Minimum elapsed time is the shortest time the student took to answer a question. This feature can capture outlier behaviors. For example, if the minimum time is significantly shorter than the average, it might indicate that the student rushed through a particular question, possibly resulting in an incorrect answer. Conversely, a very short minimum time might indicate a question that was answered confidently and correctly.

Finally, maximum elapsed time is the longest time the student took to answer a question. This feature can also capture outlier behaviors. If the maximum time is significantly longer than the average, it might suggest that the student struggled with a particular question or needed extra time to think it through.
These features, along with other features like correctness rate, provide a holistic view of the student's behavior and performance.
7. The machine learning model uses this information to learn patterns and relationships between these features and the target variable which is correctness of the next answer. Here's how the model might use these features:
First, the model can learn that students who consistently answer questions quickly, which means average elapsed time is low are more likely to answer the next question correctly if they have a high correctness rate.
Also, it can learn that students who have a history of rushing through questions, which means minimum elapsed time is low, but also have a low correctness rate are more likely to answer the next question incorrectly.
In summary, these features are valuable in understanding the dynamics of student engagement and performance in the system.

8.So, in this project, using these features, classification methods which are Decision Tree and K Nearest Neighbours algorithm were used to predict the student performance. A decision tree classifier is a machine learning algorithm that classifies students into performance categories such as high-performing, average, or low-performing based on factors like attendance and grades. During training, the algorithm creates a tree-like structure by selecting the most relevant factors and their optimal thresholds for making accurate predictions. When given a new student's information, the model navigates this tree, asking a series of questions about the student's attributes and using the answers to classify them into the appropriate performance category.

9. Then, other model is K-Nearest Neighbour. It is a classifier that makes predictions based on how similar a student is to their peers. It looks at the academic performance of nearby students, thats why it is (the "K" nearest neighbour) and classifies the student into a performance group such as high-performing, average, or low-performing based on what their similar peers have achieved.

10. Especially, to improve the accuracy of classifiers, I applied ensemble techniques on the classifiers. An ensemble technique in machine learning is a method that combines the predictions of multiple individual models to improve the overall prediction accuracy and robustness, often resulting in better performance than a single model. 

11. In this project, I used bagging, boosting and random forest in ensemble techniques. First, bagging short for Bootstrap Aggregating involves training multiple models often the same type independently on different random subsets of the training data. These models are trained in parallel, and their predictions are combined by voting for classification to make the final prediction. Second technique is boosting, it trains a series of simple models sequentially and each new model focuses on correcting the mistakes made by the previous ones by giving more weight to the data points that were incorrectly predicted. Also,Boosting combines these models' predictions to improve overall prediction accuracy. And the last technique is Random forest. It combines multiple decision trees to make predictions, improves accuracy and reduces overfitting by averaging the predictions of many individual trees. 

12. Then, to evaluate the models' performance, I used several metrics which are accuracy, precision, recall and f1-score. Accuracy measures the overall correctness of predictions.It's the ratio of correctly predicted instances to the total number of instances. And precision measures how accurate the model's positive predictions are. It tells you the proportion of correctly predicted positive instances among all the instances predicted as positive. Third is recall, it measures the ability of the model to identify all relevant instances. It tells you the proportion of correctly predicted positive instances among all the actual positive instances.In simple terms, recall tells you how well the model avoids missing positive cases. And finlly, f1-score is a single metric that balances both precision and recall. It provides a comprehensive measure of a model's accuracy by considering both false positives and false negatives.

13. This is a result table. You can observe that the performance improved significantly when ensemble techniques were used in combination with classifiers compared to using single models alone. For instance, when only the decision tree was used, the accuracy was 0.61, but when boosting was applied to the decision tree, the accuracy increased to 0.64. Similarly, with the k-nearest neighbor algorithm, using only k-NN resulted in an F1-score of 0.74, whereas applying bagging to k-NN improved the F1-score to 0.77.

14. The following table presents results with adjustments to features. It includes three performance scenarios: one considering only correctness rate, one considering only elapsed time, and one considering both correctness rate and elapsed time. Interestingly, the performance was lowest when both correctness rate and elapsed time were considered, while the highest performance result was observed when only elapsed time was taken into account. For example, when only elapsed time was used, the f1-score was 0.8, but when correctness rate and elapsed time were considered, the f1-score was 0.68. One of the reasons why combining both correctness rate and elapsed time resulted in lower performance compared to considering them separately is due to increased complexity. Combining multiple features can make the model more complex, and if the model becomes overly complex relative to the amount of data available, it can lead to poor performance on unseen data.

15. Next slide is about recommendation of questions but I didnt prepare it much. I wil explain it briefly. anyways,
 In this research, Collaborative Filtering techniques such as Singular Value Decomposition, Non-negative Matrix Factorization and Co-Clustering were used to recommend the next questions based on the student-question interaction.Collaborative Filtering is a popular recommendation approach that utilises user-item interaction data to make recommendations and is used as the predictive model in this study as it fits with the dataset, EdNet which mainly consists of interactions between students and questions. In the process of making recommendations, students are grouped based on their correctness rate and average elapsed time into "High Achievers", "Average Performers" and "Struggling Learners‚Äù. 

16. Following this, the prediction score indicating the probability of a student answering a question correctly is computed. Questions with higher prediction scores are then given to Struggling Learners, whereas questions with lower prediction scores are offered to High Achievers. Hence, different recommendations are provided for each group: Challenging questions for High Achievers, proficiency-(ÌîÑÎü¨ÌîºÏÖòÏãú)aligned questions for Average Performers and foundational support for Struggling Learners. 

17. I used Root Mean Square Error, is a measure of how accurate a prediction or model is by quantifying the average size of the errors between predicted and actual values. Smaller RMSE values indicate better accuracy. Other metric is Mean Absolute Error, it measures the average size of errors between predicted and actual values. It quantifies how far off predictions are from reality, without considering direction. also Smaller values indicate better accuracy.
The result shows that the performance of Singular Value Decompostion was better than other models.
This is the end,

aim: develop a system that predicts student performance in an adaptive learning environment and provides personalized question recommendations. 
This system aims to enhance the learning experience, tailor educational content to individual needs, and improve overall educational outcomes.

future work: Enhanced Personalization: Refine the recommendation algorithms to provide even more personalized learning experiences for students by considering additional factors such as learning styles, preferences, and strengths/weaknesses.
