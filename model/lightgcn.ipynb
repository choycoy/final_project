{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcY7v4UHal3VnOKacvvZ3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choycoy/choycoy.github.io/blob/main/lightgcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO0CPs9CqCFG"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/recommenders.git ./recommenders_microsoft"
      ],
      "metadata": {
        "id": "st8xb4GBqFUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/recommenders_microsoft')\n",
        "sys.path.append('/content/recommenders_microsoft/recommenders')"
      ],
      "metadata": {
        "id": "IpDGJxLCqFch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scrapbook"
      ],
      "metadata": {
        "id": "oHcGC7ruqF6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import scrapbook as sb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
        "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
        "from recommenders.datasets.python_splitters import python_stratified_split\n",
        "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
        "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Pandas version: {}\".format(pd.__version__))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))"
      ],
      "metadata": {
        "id": "8B-no1oXqF_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top k items to recommend\n",
        "TOP_K = 10\n",
        "\n",
        "SEED = DEFAULT_SEED  # Set None for non-deterministic results\n",
        "\n",
        "yaml_file = \"/content/recommenders_microsoft/recommenders/models/deeprec/config/lightgcn.yaml\"\n",
        "user_file = \"/content/recommenders_microsoft/recommenders/tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
        "item_file = \"/content/recommenders_microsoft/recommenders/tests/resources/deeprec/lightgcn/item_embeddings.csv\""
      ],
      "metadata": {
        "id": "PWdCfdnPqKMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aw5gny_rqM7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_name=['userID','itemID','elapsed_time', 'timestamp']\n",
        "df = pd.read_csv(\"/content/drive/My Drive/final/combined_with_filename - Copy (3).csv\",sep=\",\",names=columns_name)\n",
        "print('User Dataset 1 shape : {}'.format(df.shape))\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Nb9sdFXBqN_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(df.index[0])\n",
        "# Assuming df is your DataFrame\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "jg0eEtqiqQOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file and convert the elapsed_time column to numeric\n",
        "df['elapsed_time'] = pd.to_numeric(df['elapsed_time'])\n",
        "\n",
        "# Calculate quartiles of elapsed time\n",
        "quartiles = df['elapsed_time'].quantile([0.2, 0.4, 0.6, 0.8])\n",
        "\n",
        "# Define rating_bins based on quartiles and add 'inf' for values greater than the 80th percentile\n",
        "rating_bins = [0] + quartiles.tolist() + [float('inf')]\n",
        "\n",
        "# Create corresponding ratings based on the number of bins (5-point rating scale)\n",
        "ratings = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Create a new column for ratings\n",
        "df['rating'] = pd.cut(df['elapsed_time'], bins=rating_bins, labels=ratings, include_lowest=True)\n",
        "\n",
        "df.drop('elapsed_time', axis=1, inplace=True)\n",
        "# Print the dataframe with the new 'rating' column\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "MQZIWsTWqRzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rating'] = df['rating'].astype(float)\n",
        "df['timestamp'] = df['timestamp'].astype(float)"
      ],
      "metadata": {
        "id": "9lNQv7YWqSlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = python_stratified_split(df, ratio=0.75)"
      ],
      "metadata": {
        "id": "-7218lJRqTY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = ImplicitCF(train=train, test=test, seed=SEED)"
      ],
      "metadata": {
        "id": "ykEnourrqUed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = prepare_hparams(yaml_file,\n",
        "                          n_layers=3,\n",
        "                          batch_size= 4096,\n",
        "                          epochs=5,\n",
        "                          learning_rate=0.005,\n",
        "                          eval_epoch=5,\n",
        "                          top_k=TOP_K,\n",
        "                         )"
      ],
      "metadata": {
        "id": "QUj8spJAqWY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightGCN(hparams, data, seed=SEED)"
      ],
      "metadata": {
        "id": "kAGemMoTqXPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Timer() as train_time:\n",
        "    model.fit()\n",
        "print(\"Took {} seconds for training.\".format(train_time.interval))"
      ],
      "metadata": {
        "id": "XR9p7YdPqYJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topk_scores = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
        "\n",
        "topk_scores.head()"
      ],
      "metadata": {
        "id": "FIrM5a-hqZaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_map = map_at_k(test, topk_scores, k=TOP_K)\n",
        "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
        "eval_precision = precision_at_k(test, topk_scores, k=TOP_K)\n",
        "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
        "\n",
        "print(\"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ],
      "metadata": {
        "id": "MWTUyDj1qa2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
