Student performance indicates student’s progress or achievement in their learning activities and is utilised to evaluate their comprehension of concepts, skills and knowledge [16]. Predicting student performance is necessary to identify students who could face challenges, and can intervene early to provide timely support, personalised learning strategies, and resources to enhance their chances of success. There are primarily two methods for performance prediction: Knowledge Tracing and classification models. Knowledge Tracing (KT) estimates students’ mastery level of a concept by analysing their past performance on related learning tasks [9], i.e., KT aims to predict if they will give an accurate response to the upcoming question. Bayesian Knowledge Tracing (BKT) [11] was the most widely used method for modelling students’ knowledge states which were expressed by a binary variable indicating whether they had achieved mastery or not in the learning concept. Several extensions of BKT were suggested by including additional aspects such as exercise difficulty [12] and individual student’s characteristics [13]. Another common category of traditional Knowledge Tracing methods is factor analysis model which focuses on learning general parameters from past data to predict [17]. For instance, in order to forecast student performance, Addictive Factors Analysis Model (AFM) [27] considered students’ response times that could offer insights into the correctness of their answers and DAS3H [10] suggested encoding the question’s difficulty, student’s ability, skills and skill practice history. With the advancement of deep learning, Deep Knowledge Tracing (DKT) [19] applied Recurrent Neural Networks (RNNs) to track student’s knowledge state and calculated the probability that they would provide correct answers to questions in accordance with their levels of knowledge. On the other hand, various classification methods have been used to make predictions about students’ learning outcomes [20, 22, 23]. For example, Naïve Bayes and Logistic Regression were employed to anticipate the graduation results of engineering students based on their performance in the first three years [14] and Yaacob et al. [25] utilised Decision Tree, K-Nearest Neighbour and Neural Networks to predict undergraduate student dropout. Similarly, Yağcı [26] used Support Vector Machines to forecast students’ final exam outcomes and the predictions were made by taking into account their performance in the midterm exams. Moreover, to improve the accuracy of classifiers, applying ensemble techniques including Bagging and Boosting on the classifiers was proposed [18, 21, 24]. 
